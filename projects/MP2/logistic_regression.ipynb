{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Logistic Regression Model Evaluation",
        "CSST102 \u2013 Machine Problem No. 2  ",
        "Academic Year: 2025\u20132026  ",
        "Section: (fill in)  ",
        "Student: (fill in)",
        "",
        "This notebook follows the required workflow:",
        "1. Data preparation  ",
        "2. Train-test split (80/20)  ",
        "3. Logistic Regression training  ",
        "4. 5-Fold Cross Validation  ",
        "5. Confusion Matrix and metrics  ",
        "6. Learning Curve  ",
        "7. Interpretation",
        "",
        "The steps are aligned with the Machine Problem instructions. \u30107\u2020file\u3011",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np",
        "import pandas as pd",
        "from sklearn.datasets import load_iris",
        "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve",
        "from sklearn.preprocessing import StandardScaler",
        "from sklearn.linear_model import LogisticRegression",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report",
        "import matplotlib.pyplot as plt",
        "",
        "# 1. Load dataset",
        "iris = load_iris(as_frame=True)",
        "X = iris.data",
        "y = iris.target",
        "target_names = iris.target_names",
        "",
        "X.head()",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 2. Train-test split (80/20)",
        "X_train, X_test, y_train, y_test = train_test_split(",
        "    X, y, test_size=0.2, random_state=42, stratify=y",
        ")",
        "",
        "# 3. Feature scaling",
        "scaler = StandardScaler()",
        "X_train_scaled = scaler.fit_transform(X_train)",
        "X_test_scaled = scaler.transform(X_test)",
        "",
        "# 4. Train Logistic Regression",
        "log_reg = LogisticRegression(max_iter=1000, multi_class=\"auto\")",
        "log_reg.fit(X_train_scaled, y_train)",
        "",
        "train_accuracy = log_reg.score(X_train_scaled, y_train)",
        "test_accuracy = log_reg.score(X_test_scaled, y_test)",
        "",
        "print(\"Training Accuracy:\", train_accuracy)",
        "print(\"Testing Accuracy:\", test_accuracy)",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 5. Cross-Validation (5-Fold)",
        "X_scaled_full = StandardScaler().fit_transform(X)",
        "",
        "cv_scores = cross_val_score(",
        "    LogisticRegression(max_iter=1000, multi_class=\"auto\"),",
        "    X_scaled_full,",
        "    y,",
        "    cv=5",
        ")",
        "",
        "print(\"Cross-validation scores:\", cv_scores)",
        "print(\"Mean Accuracy:\", np.mean(cv_scores))",
        "print(\"Standard Deviation:\", np.std(cv_scores, ddof=1))",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 6. Confusion Matrix and metrics",
        "y_pred = log_reg.predict(X_test_scaled)",
        "cm = confusion_matrix(y_test, y_pred)",
        "",
        "acc = accuracy_score(y_test, y_pred)",
        "prec_macro = precision_score(y_test, y_pred, average='macro', zero_division=0)",
        "recall_macro = recall_score(y_test, y_pred, average='macro', zero_division=0)",
        "f1_macro = f1_score(y_test, y_pred, average='macro', zero_division=0)",
        "",
        "print(\"Accuracy:\", acc)",
        "print(\"Precision (macro):\", prec_macro)",
        "print(\"Recall (macro):\", recall_macro)",
        "print(\"F1-score (macro):\", f1_macro)",
        "",
        "print(\"\\nClassification Report:\")",
        "print(classification_report(y_test, y_pred, target_names=target_names))",
        "",
        "fig, ax = plt.subplots()",
        "im = ax.imshow(cm)",
        "ax.set_title(\"Confusion Matrix (Logistic Regression)\")",
        "ax.set_xlabel(\"Predicted label\")",
        "ax.set_ylabel(\"True label\")",
        "ax.set_xticks(range(len(target_names)))",
        "ax.set_yticks(range(len(target_names)))",
        "ax.set_xticklabels(target_names, rotation=45, ha=\"right\")",
        "ax.set_yticklabels(target_names)",
        "",
        "for (i, j), val in np.ndenumerate(cm):",
        "    ax.text(j, i, str(val), ha='center', va='center')",
        "",
        "plt.tight_layout()",
        "plt.show()",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 7. Learning Curve",
        "train_sizes, train_scores, test_scores = learning_curve(",
        "    LogisticRegression(max_iter=1000, multi_class=\"auto\"),",
        "    X_scaled_full,",
        "    y,",
        "    cv=5,",
        "    train_sizes=np.linspace(0.1, 1.0, 10),",
        "    shuffle=True,",
        "    random_state=42",
        ")",
        "",
        "train_scores_mean = train_scores.mean(axis=1)",
        "test_scores_mean = test_scores.mean(axis=1)",
        "",
        "plt.figure()",
        "plt.plot(train_sizes, train_scores_mean, marker='o', label=\"Training score\")",
        "plt.plot(train_sizes, test_scores_mean, marker='o', label=\"Cross-validation score\")",
        "plt.title(\"Learning Curve (Logistic Regression)\")",
        "plt.xlabel(\"Training set size (samples)\")",
        "plt.ylabel(\"Accuracy\")",
        "plt.legend()",
        "plt.grid(True)",
        "plt.show()",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Notes / Reflection",
        "- The confusion matrix shows strong classification performance with most predictions on the diagonal, meaning predicted class = true class.",
        "- Cross-validation mean accuracy is 0.9600 with std dev 0.0435, which means the model is consistently good across folds.",
        "- The learning curve shows the training and validation accuracy lines getting closer as data size increases, suggesting the model is not heavily overfitting. \u30107\u2020file\u3011",
        "",
        "For the full interpretation and suggested improvements, see `report.docx`. \u30107\u2020file\u3011",
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}